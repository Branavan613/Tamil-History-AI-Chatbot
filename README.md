# Tamil-History-AI-Chatbot
A lot of Sri Lankan history isn't pretty, and it isn't largely shared. Due to censorship and media bias, tamil history has been somewhat forgotten. So, as a part of the Ottawa Tamil Association, I have built an AI Chatbot, fed with hundreds of historical news reports, articles, and papers, to help young tamilians educate and learn about their history.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Project Overview](#project-overview)
- [Dependencies](#dependencies)
- [Contributing](#contributing)
- [License](#license)

## Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/Tamil-History-AI-chatbot.git
cd Tamil-History-AI-history-chatbot
```

2. Install the required dependencies:
Ensure you have Python 3.8+ installed. Then, download the dependencies from the requirements.txt file:

3. Set up environment variables:
- Add your GROQ_API_KEY to the .env file:

4. Install ollama:
Follow the instructions on the Ollama GitHub page or the official website to install the ollama CLI tool.

5. Pull the required model:

6. After installing ollama, run the following command to pull the nomic-embed-text model:
```bash
ollama pull nomic-embed-text
```

## Usage

To start the chatbot, simply run the main function:

Once running, you'll be prompted to ask any question related to Sri Lankan history. The chatbot will generate relevant search queries, retrieve information from a document collection, and provide a concise answer.

## Project Overview

### Main Components

- **Multiquery:**  
  Generates three alternative search queries to provide diverse perspectives on the user's question.
  
- **Document Retrieval:**  
  Uses embeddings generated by the `ollama` library to find the most relevant documents in the collection and extract pertinent information.

- **OTA_speech_chat_completion:**  
  Produces a detailed answer to the user's question using a pre-trained language model and relevant document excerpts.

- **Asynchronous Execution:**  
  The chatbot uses Python's `asyncio` for handling tasks concurrently, such as querying documents and generating responses.

### Document Storage and Retrieval

- **ChromaDB:**  
  The project uses `chromadb` to store document embeddings and efficiently retrieve relevant excerpts based on user queries.

## Dependencies

The project relies on the following Python libraries:

- **`asyncio`:** For asynchronous programming.
- **`groq`:** To interact with the Groq client for AI tasks.
- **`langchain`, `langchain_community`, `langchain_huggingface`:** For text processing, embedding generation, and model integration.
- **`ollama`:** For generating embe

## Contributing
Contributions are welcome! Please submit a pull request or open an issue for any suggestions or improvements.

## License
This project is licensed under the MIT License. 
